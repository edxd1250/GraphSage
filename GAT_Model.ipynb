{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 881 Project\n",
    "**Group Names: Edmond Anderson, Sarah Bradford, Lacey Hamilton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from scipy import sparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data_2024')\n",
    "adj_matrix = sparse.load_npz(path/'adj.npz')\n",
    "feat  = np.load(path/'features.npy')\n",
    "labels = np.load(path/'labels.npy')\n",
    "splits = json.load(open(path/'splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 2480)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('/Users/sarahbradford/Downloads/data_2024/adj.npz')\n",
    "adj_matrix = sparse.csr_matrix((adj['data'], adj['indices'], adj['indptr']), shape=adj['shape'])\n",
    "feat = np.load('/Users/sarahbradford/Downloads/data_2024/features.npy')\n",
    "labels = np.load('/Users/sarahbradford/Downloads/data_2024/labels.npy')\n",
    "with open('/Users/sarahbradford/Downloads/data_2024/splits.json') as f:\n",
    "    splits = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index dimension must be 1 or 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adj_matrix \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsr_matrix((\u001b[43madj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, adj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m'\u001b[39m], adj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindptr\u001b[39m\u001b[38;5;124m'\u001b[39m]), shape\u001b[38;5;241m=\u001b[39madj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/scipy/sparse/_index.py:46\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m---> 46\u001b[0m     row, col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indices(key)\n\u001b[1;32m     48\u001b[0m     \u001b[39m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/scipy/sparse/_index.py:158\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    156\u001b[0m         row \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m M\n\u001b[1;32m    157\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(row, \u001b[39mslice\u001b[39m):\n\u001b[0;32m--> 158\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_asindices(row, M)\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m isintlike(col):\n\u001b[1;32m    161\u001b[0m     col \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(col)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/scipy/sparse/_index.py:182\u001b[0m, in \u001b[0;36mIndexMixin._asindices\u001b[0;34m(self, idx, length)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid index\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mIndex dimension must be 1 or 2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mIndexError\u001b[0m: Index dimension must be 1 or 2"
     ]
    }
   ],
   "source": [
    "adj_matrix = sparse.csr_matrix((adj['data'], adj['indices'], adj['indptr']), shape=adj['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = torch.FloatTensor(adj_matrix.toarray())\n",
    "node_features = torch.FloatTensor(feat)\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, adj_matrix, node_features, labels):\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.node_features = node_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adj_matrix[idx], self.node_features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx_train', 'idx_test'])\n"
     ]
    }
   ],
   "source": [
    "print(splits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = splits['idx_train']\n",
    "idx_test = splits['idx_test']\n",
    "idx_train = [idx for idx in idx_train if idx < len(labels)]\n",
    "idx_test = [idx for idx in idx_test if idx < len(labels)]\n",
    "# idx_train.sort()\n",
    "# idx_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphDataset(adj_matrix[idx_train], node_features[idx_train], labels[idx_train])\n",
    "test_dataset = GraphDataset(adj_matrix[idx_test], node_features[idx_test], labels[idx_test])\n",
    "#val_dataset = GraphDataset(adj_matrix[idx_val], node_features[idx_val], labels[idx_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the GAT layer\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        self.attn_fc = nn.Linear(2 * out_features, 1)\n",
    "\n",
    "    def forward(self, adj_matrix, node_features):\n",
    "        h = self.fc(node_features)\n",
    "        N = h.size()[0]\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.zeros(N, N)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if adj_matrix[i, j] == 1:\n",
    "                    attn_input = torch.cat([h[i], h[j]], dim=0)\n",
    "                    attn_scores[i, j] = self.attn_fc(attn_input).squeeze()\n",
    "\n",
    "        # Compute attention coefficients\n",
    "        attn_coefficients = nn.functional.softmax(attn_scores, dim=1)\n",
    "\n",
    "        # Compute output features\n",
    "        h_prime = torch.zeros(N, h.size()[1])\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                h_prime[i] += attn_coefficients[i, j] * h[j]\n",
    "\n",
    "        return h_prime\n",
    "# defining th GAT model\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATLayer(in_features, hidden_features)\n",
    "        self.layer2 = GATLayer(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, adj_matrix, node_features):\n",
    "        h = self.layer1(adj_matrix, node_features)\n",
    "        h = torch.relu(h)\n",
    "        h = self.layer2(adj_matrix, h)\n",
    "        return h\n",
    "# GAT model\n",
    "model = GAT(in_features=node_features.size()[1], hidden_features=8, out_features=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.845\n",
      "[2] loss: 1.455\n",
      "[3] loss: 0.937\n",
      "[4] loss: 0.534\n",
      "[5] loss: 0.327\n",
      "[6] loss: 0.228\n",
      "[7] loss: 0.162\n",
      "[8] loss: 0.129\n",
      "[9] loss: 0.094\n",
      "[10] loss: 0.065\n",
      "[11] loss: 0.054\n",
      "[12] loss: 0.047\n",
      "[13] loss: 0.044\n",
      "[14] loss: 0.040\n",
      "[15] loss: 0.021\n",
      "[16] loss: 0.017\n",
      "[17] loss: 0.015\n",
      "[18] loss: 0.013\n",
      "[19] loss: 0.012\n",
      "[20] loss: 0.012\n",
      "[21] loss: 0.011\n",
      "[22] loss: 0.010\n",
      "[23] loss: 0.009\n",
      "[24] loss: 0.009\n",
      "[25] loss: 0.009\n",
      "[26] loss: 0.008\n",
      "[27] loss: 0.007\n",
      "[28] loss: 0.006\n",
      "[29] loss: 0.006\n",
      "[30] loss: 0.006\n",
      "[31] loss: 0.005\n",
      "[32] loss: 0.005\n",
      "[33] loss: 0.005\n",
      "[34] loss: 0.005\n",
      "[35] loss: 0.004\n",
      "[36] loss: 0.004\n",
      "[37] loss: 0.004\n",
      "[38] loss: 0.004\n",
      "[39] loss: 0.003\n",
      "[40] loss: 0.003\n",
      "[41] loss: 0.003\n",
      "[42] loss: 0.003\n",
      "[43] loss: 0.002\n",
      "[44] loss: 0.002\n",
      "[45] loss: 0.002\n",
      "[46] loss: 0.002\n",
      "[47] loss: 0.002\n",
      "[48] loss: 0.002\n",
      "[49] loss: 0.002\n",
      "[50] loss: 0.002\n",
      "Accuracy: 20 %\n"
     ]
    }
   ],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# train the model\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        adj_matrix, node_features, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(adj_matrix, node_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "# model testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        adj_matrix, node_features, labels = data\n",
    "        outputs = model(adj_matrix, node_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.842\n",
      "[2] loss: 1.682\n",
      "[3] loss: 1.388\n",
      "[4] loss: 1.058\n",
      "[5] loss: 0.843\n",
      "[6] loss: 0.626\n",
      "[7] loss: 0.525\n",
      "[8] loss: 0.421\n",
      "[9] loss: 0.454\n",
      "[10] loss: 0.388\n",
      "[11] loss: 0.242\n",
      "[12] loss: 0.229\n",
      "[13] loss: 0.227\n",
      "[14] loss: 0.149\n",
      "[15] loss: 0.229\n",
      "[16] loss: 0.148\n",
      "[17] loss: 0.122\n",
      "[18] loss: 0.105\n",
      "[19] loss: 0.111\n",
      "[20] loss: 0.101\n",
      "[21] loss: 0.094\n",
      "[22] loss: 0.085\n",
      "[23] loss: 0.083\n",
      "[24] loss: 0.075\n",
      "[25] loss: 0.083\n",
      "[26] loss: 0.079\n",
      "[27] loss: 0.076\n",
      "[28] loss: 0.071\n",
      "[29] loss: 0.191\n",
      "[30] loss: 0.081\n",
      "[31] loss: 0.065\n",
      "[32] loss: 0.102\n",
      "[33] loss: 0.069\n",
      "[34] loss: 0.072\n",
      "[35] loss: 0.070\n",
      "[36] loss: 0.068\n",
      "[37] loss: 0.067\n",
      "[38] loss: 0.066\n",
      "[39] loss: 0.227\n",
      "[40] loss: 0.281\n",
      "[41] loss: 0.146\n",
      "[42] loss: 0.242\n",
      "[43] loss: 0.372\n",
      "[44] loss: 0.169\n",
      "[45] loss: 0.156\n",
      "[46] loss: 0.110\n",
      "[47] loss: 0.103\n",
      "[48] loss: 0.101\n",
      "[49] loss: 0.098\n",
      "[50] loss: 0.097\n",
      "[51] loss: 0.096\n",
      "[52] loss: 0.096\n",
      "[53] loss: 0.095\n",
      "[54] loss: 0.095\n",
      "[55] loss: 0.097\n",
      "[56] loss: 0.093\n",
      "[57] loss: 0.095\n",
      "[58] loss: 0.094\n",
      "[59] loss: 0.095\n",
      "[60] loss: 0.096\n",
      "[61] loss: 0.094\n",
      "[62] loss: 0.094\n",
      "[63] loss: 0.095\n",
      "[64] loss: 0.094\n",
      "[65] loss: 0.093\n",
      "[66] loss: 0.094\n",
      "[67] loss: 0.095\n",
      "[68] loss: 0.093\n",
      "[69] loss: 0.093\n",
      "[70] loss: 0.094\n",
      "[71] loss: 0.093\n",
      "[72] loss: 0.091\n",
      "[73] loss: 0.093\n",
      "[74] loss: 0.094\n",
      "[75] loss: 0.095\n",
      "[76] loss: 0.093\n",
      "[77] loss: 0.094\n",
      "[78] loss: 0.094\n",
      "[79] loss: 0.093\n",
      "[80] loss: 0.094\n",
      "[81] loss: 0.093\n",
      "[82] loss: 0.092\n",
      "[83] loss: 0.092\n",
      "[84] loss: 0.093\n",
      "[85] loss: 0.093\n",
      "[86] loss: 0.092\n",
      "[87] loss: 0.092\n",
      "[88] loss: 0.092\n",
      "[89] loss: 0.092\n",
      "[90] loss: 0.092\n",
      "[91] loss: 0.093\n",
      "[92] loss: 0.096\n",
      "[93] loss: 0.092\n",
      "[94] loss: 0.093\n",
      "[95] loss: 0.092\n",
      "[96] loss: 0.092\n",
      "[97] loss: 0.091\n",
      "[98] loss: 0.092\n",
      "[99] loss: 0.092\n",
      "[100] loss: 0.091\n",
      "Accuracy: 17 %\n"
     ]
    }
   ],
   "source": [
    "# improve the accuracy by adding more layers\n",
    "class ImprovedGAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(ImprovedGAT, self).__init__()\n",
    "        self.layer1 = GATLayer(in_features, hidden_features)\n",
    "        self.layer2 = GATLayer(hidden_features, hidden_features)\n",
    "        self.layer3 = GATLayer(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, adj_matrix, node_features):\n",
    "        h = self.layer1(adj_matrix, node_features)\n",
    "        h = torch.relu(h)\n",
    "        h = self.layer2(adj_matrix, h)\n",
    "        h = torch.relu(h)\n",
    "        h = self.layer3(adj_matrix, h)\n",
    "        return h\n",
    "# Improved GAT model\n",
    "model = ImprovedGAT(in_features=node_features.size()[1], hidden_features=8, out_features=7)\n",
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# train the model\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        adj_matrix, node_features, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(adj_matrix, node_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "# model testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        adj_matrix, node_features, labels = data\n",
    "        outputs = model(adj_matrix, node_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m, in \u001b[0;36mImprovedGAT.forward\u001b[0;34m(self, adj_matrix, node_features)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, adj_matrix, node_features):\n\u001b[0;32m---> 10\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[1;32m     12\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(adj_matrix, h)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GraphSage/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mGATLayer.forward\u001b[0;34m(self, adj_matrix, node_features)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43madj_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     17\u001b[0m             attn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h[i], h[j]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m             attn_scores[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_fc(attn_input)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pred = model(test_loader,node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m[idx_test]\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, preds, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "preds = pred[idx_test]\n",
    "np.savetxt('submission.txt', preds, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "605cf7bcaa80724d107f41962e778124ae33e6c6d0f7e8df414b9d839a160efd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
