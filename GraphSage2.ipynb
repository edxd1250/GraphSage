{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218fe1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "path = Path('data_2024')\n",
    "adj = sp.load_npz(path/'adj.npz')\n",
    "feat  = np.load(path/'features.npy')\n",
    "labels = np.load(path/'labels.npy')\n",
    "splits = json.load(open(path/'splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9ef4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537f9b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2119,\n",
       " 2206,\n",
       " 2165,\n",
       " 1994,\n",
       " 520,\n",
       " 521,\n",
       " 2103,\n",
       " 1838,\n",
       " 1840,\n",
       " 116,\n",
       " 134,\n",
       " 2477,\n",
       " 1522,\n",
       " 821,\n",
       " 1393,\n",
       " 1983,\n",
       " 2136,\n",
       " 2478,\n",
       " 1182,\n",
       " 1617,\n",
       " 899,\n",
       " 1898,\n",
       " 1592,\n",
       " 903,\n",
       " 815,\n",
       " 1395,\n",
       " 871,\n",
       " 1596,\n",
       " 1188,\n",
       " 513,\n",
       " 791,\n",
       " 1296,\n",
       " 1608,\n",
       " 1149,\n",
       " 1568,\n",
       " 1625,\n",
       " 1101,\n",
       " 829,\n",
       " 1595,\n",
       " 1912,\n",
       " 1856,\n",
       " 308,\n",
       " 603,\n",
       " 1122,\n",
       " 566,\n",
       " 2175,\n",
       " 2066,\n",
       " 1556,\n",
       " 339,\n",
       " 1264,\n",
       " 531,\n",
       " 2266,\n",
       " 3,\n",
       " 191,\n",
       " 423,\n",
       " 2054,\n",
       " 1098,\n",
       " 338,\n",
       " 2215,\n",
       " 2184,\n",
       " 302,\n",
       " 982,\n",
       " 725,\n",
       " 362,\n",
       " 1931,\n",
       " 2178,\n",
       " 745,\n",
       " 1248,\n",
       " 376,\n",
       " 171,\n",
       " 646,\n",
       " 1569,\n",
       " 1778,\n",
       " 1974,\n",
       " 321,\n",
       " 156,\n",
       " 2265,\n",
       " 1814,\n",
       " 1050,\n",
       " 868,\n",
       " 846,\n",
       " 1969,\n",
       " 2382,\n",
       " 1508,\n",
       " 636,\n",
       " 428,\n",
       " 2164,\n",
       " 1044,\n",
       " 1378,\n",
       " 2259,\n",
       " 1265,\n",
       " 809,\n",
       " 2387,\n",
       " 1056,\n",
       " 268,\n",
       " 1459,\n",
       " 1509,\n",
       " 1158,\n",
       " 1107,\n",
       " 1024,\n",
       " 755,\n",
       " 293,\n",
       " 2218,\n",
       " 194,\n",
       " 770,\n",
       " 661,\n",
       " 757,\n",
       " 1450,\n",
       " 1328,\n",
       " 1151,\n",
       " 986,\n",
       " 1256,\n",
       " 325,\n",
       " 827,\n",
       " 1300,\n",
       " 1890,\n",
       " 607,\n",
       " 76,\n",
       " 292,\n",
       " 2237,\n",
       " 236,\n",
       " 1474,\n",
       " 203,\n",
       " 1065,\n",
       " 2317,\n",
       " 724,\n",
       " 2308,\n",
       " 2236,\n",
       " 100,\n",
       " 1423,\n",
       " 1824,\n",
       " 140,\n",
       " 1641,\n",
       " 148,\n",
       " 1672,\n",
       " 1540,\n",
       " 240,\n",
       " 2145,\n",
       " 364,\n",
       " 1291,\n",
       " 921,\n",
       " 637,\n",
       " 1085,\n",
       " 1484,\n",
       " 139,\n",
       " 1587,\n",
       " 758,\n",
       " 974,\n",
       " 1257,\n",
       " 1476,\n",
       " 43,\n",
       " 878,\n",
       " 2263,\n",
       " 819,\n",
       " 391,\n",
       " 283,\n",
       " 1426,\n",
       " 1713,\n",
       " 1800,\n",
       " 2148,\n",
       " 701,\n",
       " 663,\n",
       " 2003,\n",
       " 1103,\n",
       " 1148,\n",
       " 658,\n",
       " 1124,\n",
       " 444,\n",
       " 1041,\n",
       " 1512,\n",
       " 618,\n",
       " 1701,\n",
       " 1465,\n",
       " 2471,\n",
       " 1644,\n",
       " 1609,\n",
       " 1620,\n",
       " 1268,\n",
       " 726,\n",
       " 2245,\n",
       " 2052,\n",
       " 48,\n",
       " 1271,\n",
       " 220,\n",
       " 1972,\n",
       " 2061,\n",
       " 1788,\n",
       " 1069,\n",
       " 1470,\n",
       " 402,\n",
       " 2284,\n",
       " 1783,\n",
       " 941,\n",
       " 2443,\n",
       " 1607,\n",
       " 535,\n",
       " 1278,\n",
       " 495,\n",
       " 1156,\n",
       " 694,\n",
       " 1092,\n",
       " 2114,\n",
       " 1934,\n",
       " 1458,\n",
       " 92,\n",
       " 1211,\n",
       " 1773,\n",
       " 1683,\n",
       " 381,\n",
       " 613,\n",
       " 73,\n",
       " 2059,\n",
       " 1981,\n",
       " 1571,\n",
       " 252,\n",
       " 1456,\n",
       " 1007,\n",
       " 639,\n",
       " 1175,\n",
       " 375,\n",
       " 1270,\n",
       " 59,\n",
       " 434,\n",
       " 2254,\n",
       " 1089,\n",
       " 763,\n",
       " 683,\n",
       " 2314,\n",
       " 1006,\n",
       " 2243,\n",
       " 1555,\n",
       " 417,\n",
       " 132,\n",
       " 397,\n",
       " 1254,\n",
       " 1468,\n",
       " 582,\n",
       " 807,\n",
       " 144,\n",
       " 2472,\n",
       " 731,\n",
       " 744,\n",
       " 1398,\n",
       " 1072,\n",
       " 1887,\n",
       " 638,\n",
       " 427,\n",
       " 1708,\n",
       " 479,\n",
       " 2410,\n",
       " 1746,\n",
       " 1993,\n",
       " 1591,\n",
       " 1369,\n",
       " 291,\n",
       " 2177,\n",
       " 1042,\n",
       " 58,\n",
       " 1014,\n",
       " 1396,\n",
       " 347,\n",
       " 1850,\n",
       " 2095,\n",
       " 89,\n",
       " 2258,\n",
       " 991,\n",
       " 52,\n",
       " 2077,\n",
       " 2005,\n",
       " 1100,\n",
       " 1980,\n",
       " 2089,\n",
       " 537,\n",
       " 713,\n",
       " 946,\n",
       " 814,\n",
       " 154,\n",
       " 84,\n",
       " 1252,\n",
       " 524,\n",
       " 1068,\n",
       " 1157,\n",
       " 1673,\n",
       " 87,\n",
       " 1570,\n",
       " 1605,\n",
       " 195,\n",
       " 817,\n",
       " 1299,\n",
       " 647,\n",
       " 1184,\n",
       " 559,\n",
       " 2372,\n",
       " 1311,\n",
       " 542,\n",
       " 540,\n",
       " 923,\n",
       " 1046,\n",
       " 424,\n",
       " 838,\n",
       " 2442,\n",
       " 940,\n",
       " 482,\n",
       " 259,\n",
       " 1769,\n",
       " 1452,\n",
       " 377,\n",
       " 928,\n",
       " 805,\n",
       " 2360,\n",
       " 1599,\n",
       " 1260,\n",
       " 501,\n",
       " 2042,\n",
       " 1843,\n",
       " 1187,\n",
       " 2446,\n",
       " 1970,\n",
       " 324,\n",
       " 2049,\n",
       " 1030,\n",
       " 305,\n",
       " 1377,\n",
       " 938,\n",
       " 687,\n",
       " 1541,\n",
       " 1751,\n",
       " 36,\n",
       " 1502,\n",
       " 2074,\n",
       " 2036,\n",
       " 712,\n",
       " 2475,\n",
       " 1749,\n",
       " 994,\n",
       " 722,\n",
       " 2204,\n",
       " 2301,\n",
       " 1709,\n",
       " 558,\n",
       " 1091,\n",
       " 164,\n",
       " 1391,\n",
       " 1245,\n",
       " 743,\n",
       " 2298,\n",
       " 463,\n",
       " 1885,\n",
       " 290,\n",
       " 1303,\n",
       " 984,\n",
       " 1926,\n",
       " 1590,\n",
       " 2015,\n",
       " 301,\n",
       " 1601,\n",
       " 1552,\n",
       " 1680,\n",
       " 631,\n",
       " 1386,\n",
       " 780,\n",
       " 879,\n",
       " 1962,\n",
       " 88,\n",
       " 1222,\n",
       " 1416,\n",
       " 920,\n",
       " 1925,\n",
       " 1497,\n",
       " 1837,\n",
       " 772,\n",
       " 95,\n",
       " 935,\n",
       " 1008,\n",
       " 2421,\n",
       " 13,\n",
       " 1059,\n",
       " 1422,\n",
       " 2094,\n",
       " 1623,\n",
       " 342,\n",
       " 1975,\n",
       " 1165,\n",
       " 792,\n",
       " 2239,\n",
       " 1281,\n",
       " 1204,\n",
       " 1879,\n",
       " 60,\n",
       " 1781,\n",
       " 1857,\n",
       " 1033,\n",
       " 1772,\n",
       " 173,\n",
       " 2451,\n",
       " 2273,\n",
       " 1665,\n",
       " 910,\n",
       " 404,\n",
       " 68,\n",
       " 750,\n",
       " 411,\n",
       " 795,\n",
       " 1564,\n",
       " 1294,\n",
       " 624,\n",
       " 1112,\n",
       " 2412,\n",
       " 1424,\n",
       " 416,\n",
       " 1792,\n",
       " 24,\n",
       " 500,\n",
       " 2344,\n",
       " 1735,\n",
       " 1135,\n",
       " 146,\n",
       " 1332,\n",
       " 2376,\n",
       " 1451,\n",
       " 852,\n",
       " 26,\n",
       " 2440,\n",
       " 1548,\n",
       " 2223,\n",
       " 1523,\n",
       " 802,\n",
       " 329,\n",
       " 734,\n",
       " 1888,\n",
       " 1553,\n",
       " 189,\n",
       " 300,\n",
       " 178,\n",
       " 12,\n",
       " 1408,\n",
       " 2252,\n",
       " 165,\n",
       " 65,\n",
       " 1734,\n",
       " 1093,\n",
       " 979,\n",
       " 564,\n",
       " 1104,\n",
       " 1383,\n",
       " 863,\n",
       " 1473,\n",
       " 793,\n",
       " 2321,\n",
       " 449,\n",
       " 1762,\n",
       " 1118,\n",
       " 1765,\n",
       " 1240,\n",
       " 1514,\n",
       " 2128,\n",
       " 1467,\n",
       " 1630,\n",
       " 1694,\n",
       " 1272,\n",
       " 387,\n",
       " 2151,\n",
       " 570,\n",
       " 1392,\n",
       " 528,\n",
       " 368,\n",
       " 889,\n",
       " 2182,\n",
       " 577,\n",
       " 2166,\n",
       " 554,\n",
       " 1075,\n",
       " 2426,\n",
       " 1073,\n",
       " 2203,\n",
       " 2436,\n",
       " 1639,\n",
       " 1525,\n",
       " 288,\n",
       " 749,\n",
       " 216,\n",
       " 1667,\n",
       " 30,\n",
       " 208,\n",
       " 1403,\n",
       " 1193,\n",
       " 1809,\n",
       " 1121,\n",
       " 1720,\n",
       " 2419,\n",
       " 2038,\n",
       " 1727,\n",
       " 708,\n",
       " 828,\n",
       " 769,\n",
       " 1666,\n",
       " 2170,\n",
       " 2441,\n",
       " 1127,\n",
       " 1320,\n",
       " 136,\n",
       " 1738,\n",
       " 1634,\n",
       " 2133,\n",
       " 739,\n",
       " 1128,\n",
       " 958,\n",
       " 2464,\n",
       " 1566,\n",
       " 1764,\n",
       " 118,\n",
       " 465,\n",
       " 1950,\n",
       " 1760,\n",
       " 837,\n",
       " 1967,\n",
       " 142,\n",
       " 1365,\n",
       " 925,\n",
       " 420,\n",
       " 1275,\n",
       " 782,\n",
       " 998,\n",
       " 255,\n",
       " 408,\n",
       " 1504,\n",
       " 1668,\n",
       " 1145,\n",
       " 496,\n",
       " 2407,\n",
       " 281,\n",
       " 2385,\n",
       " 1334,\n",
       " 1302,\n",
       " 719,\n",
       " 179,\n",
       " 1176,\n",
       " 1757,\n",
       " 1183,\n",
       " 662,\n",
       " 2037,\n",
       " 2233,\n",
       " 1600,\n",
       " 1285,\n",
       " 1785,\n",
       " 2016,\n",
       " 1138,\n",
       " 390,\n",
       " 2313,\n",
       " 1083,\n",
       " 235,\n",
       " 2116,\n",
       " 997,\n",
       " 201,\n",
       " 525,\n",
       " 2027,\n",
       " 232,\n",
       " 906,\n",
       " 1611,\n",
       " 1615,\n",
       " 1400,\n",
       " 1920,\n",
       " 1039,\n",
       " 2398,\n",
       " 2413,\n",
       " 1441,\n",
       " 1733,\n",
       " 1261,\n",
       " 109,\n",
       " 1126,\n",
       " 1870,\n",
       " 1200,\n",
       " 2046,\n",
       " 326,\n",
       " 2433,\n",
       " 320,\n",
       " 2140,\n",
       " 1340,\n",
       " 2009,\n",
       " 942,\n",
       " 2141,\n",
       " 1478,\n",
       " 1048,\n",
       " 595,\n",
       " 2332,\n",
       " 2004,\n",
       " 684,\n",
       " 660,\n",
       " 1040,\n",
       " 1172,\n",
       " 488,\n",
       " 504,\n",
       " 555,\n",
       " 1436,\n",
       " 1005,\n",
       " 1140,\n",
       " 760,\n",
       " 1952,\n",
       " 623,\n",
       " 930,\n",
       " 1938,\n",
       " 2159,\n",
       " 678,\n",
       " 1244,\n",
       " 2468,\n",
       " 1798,\n",
       " 2476,\n",
       " 1768,\n",
       " 63,\n",
       " 1808,\n",
       " 273,\n",
       " 967,\n",
       " 1544,\n",
       " 2288,\n",
       " 2363,\n",
       " 1711,\n",
       " 676,\n",
       " 2195,\n",
       " 1250,\n",
       " 2380,\n",
       " 1018,\n",
       " 672,\n",
       " 553,\n",
       " 222,\n",
       " 1821,\n",
       " 1621,\n",
       " 989,\n",
       " 1105,\n",
       " 860,\n",
       " 1796,\n",
       " 241,\n",
       " 1507,\n",
       " 1413,\n",
       " 1031,\n",
       " 936,\n",
       " 957,\n",
       " 137,\n",
       " 1045,\n",
       " 775,\n",
       " 1381,\n",
       " 839,\n",
       " 1804,\n",
       " 2147,\n",
       " 275,\n",
       " 2390,\n",
       " 2255,\n",
       " 262,\n",
       " 1917,\n",
       " 778,\n",
       " 2073,\n",
       " 2296,\n",
       " 2143,\n",
       " 918,\n",
       " 916,\n",
       " 1581,\n",
       " 1132,\n",
       " 659,\n",
       " 307,\n",
       " 61,\n",
       " 1859,\n",
       " 2322,\n",
       " 2469,\n",
       " 374,\n",
       " 669,\n",
       " 1196,\n",
       " 1987,\n",
       " 72,\n",
       " 953,\n",
       " 448,\n",
       " 166,\n",
       " 1614,\n",
       " 2256,\n",
       " 1603,\n",
       " 1226,\n",
       " 714,\n",
       " 1060,\n",
       " 353,\n",
       " 248,\n",
       " 1335,\n",
       " 1359,\n",
       " 665,\n",
       " 1446,\n",
       " 2323,\n",
       " 1488,\n",
       " 2430,\n",
       " 1900,\n",
       " 454,\n",
       " 57,\n",
       " 1763,\n",
       " 101,\n",
       " 949,\n",
       " 401,\n",
       " 238,\n",
       " 866,\n",
       " 718,\n",
       " 2112,\n",
       " 1054,\n",
       " 1520,\n",
       " 67,\n",
       " 441,\n",
       " 1223,\n",
       " 117,\n",
       " 1580,\n",
       " 27,\n",
       " 2458,\n",
       " 1219,\n",
       " 1394,\n",
       " 1518,\n",
       " 556,\n",
       " 344,\n",
       " 224,\n",
       " 1684,\n",
       " 869,\n",
       " 498,\n",
       " 698,\n",
       " 2474,\n",
       " 2219,\n",
       " 1930,\n",
       " 1020,\n",
       " 2343,\n",
       " 1632,\n",
       " 1940,\n",
       " 635,\n",
       " 1921,\n",
       " 1761,\n",
       " 1146,\n",
       " 1180,\n",
       " 2261,\n",
       " 877,\n",
       " 1954,\n",
       " 987,\n",
       " 1374,\n",
       " 168,\n",
       " 2386,\n",
       " 847,\n",
       " 1730,\n",
       " 299,\n",
       " 1361,\n",
       " 1531,\n",
       " 340,\n",
       " 352,\n",
       " 1388,\n",
       " 229,\n",
       " 851,\n",
       " 1471,\n",
       " 2088,\n",
       " 1207,\n",
       " 1448,\n",
       " 1013,\n",
       " 2109,\n",
       " 373,\n",
       " 2190,\n",
       " 573,\n",
       " 567,\n",
       " 108,\n",
       " 1739,\n",
       " 1854,\n",
       " 2424,\n",
       " 654,\n",
       " 93,\n",
       " 1262,\n",
       " 2194,\n",
       " 2179,\n",
       " 199,\n",
       " 1111,\n",
       " 1841,\n",
       " 1277,\n",
       " 1706,\n",
       " 50,\n",
       " 1533,\n",
       " 625,\n",
       " 1439,\n",
       " 2173,\n",
       " 1573,\n",
       " 1936,\n",
       " 1971,\n",
       " 1855,\n",
       " 162,\n",
       " 1649,\n",
       " 2356,\n",
       " 1025,\n",
       " 924,\n",
       " 192,\n",
       " 1700,\n",
       " 973,\n",
       " 1759,\n",
       " 1095,\n",
       " 97,\n",
       " 1412,\n",
       " 357,\n",
       " 2022,\n",
       " 1747,\n",
       " 1205,\n",
       " 703,\n",
       " 1883,\n",
       " 1779,\n",
       " 934,\n",
       " 1645,\n",
       " 243,\n",
       " 1119,\n",
       " 2262,\n",
       " 675,\n",
       " 615,\n",
       " 1437,\n",
       " 276,\n",
       " 1557,\n",
       " 1963,\n",
       " 2235,\n",
       " 2418,\n",
       " 1049,\n",
       " 1479,\n",
       " 271,\n",
       " 585,\n",
       " 1051,\n",
       " 1214,\n",
       " 2031,\n",
       " 1333,\n",
       " 1613,\n",
       " 530,\n",
       " 1891,\n",
       " 2053,\n",
       " 1102,\n",
       " 891,\n",
       " 227,\n",
       " 622,\n",
       " 2012,\n",
       " 2392,\n",
       " 1827,\n",
       " 1418,\n",
       " 1895,\n",
       " 1637,\n",
       " 1229,\n",
       " 1789,\n",
       " 1537,\n",
       " 2432,\n",
       " 1521,\n",
       " 1538,\n",
       " 1206,\n",
       " 456,\n",
       " 193,\n",
       " 1648,\n",
       " 523,\n",
       " 2118,\n",
       " 512,\n",
       " 1836,\n",
       " 486,\n",
       " 251,\n",
       " 859,\n",
       " 947,\n",
       " 872,\n",
       " 2050,\n",
       " 1633,\n",
       " 2351,\n",
       " 733,\n",
       " 2212,\n",
       " 2251,\n",
       " 1830,\n",
       " 1597,\n",
       " 1263,\n",
       " 912,\n",
       " 617,\n",
       " 913,\n",
       " 246,\n",
       " 1425,\n",
       " 187,\n",
       " 1721,\n",
       " 1526,\n",
       " 16,\n",
       " 1852,\n",
       " 438,\n",
       " 1297,\n",
       " 951,\n",
       " 583,\n",
       " 1894,\n",
       " 221,\n",
       " 575,\n",
       " 568,\n",
       " 2220,\n",
       " 1943,\n",
       " 1061,\n",
       " 367,\n",
       " 429,\n",
       " 372,\n",
       " 975,\n",
       " 1780,\n",
       " 644,\n",
       " 2396,\n",
       " 580,\n",
       " 1822,\n",
       " 1360,\n",
       " 230,\n",
       " 1911,\n",
       " 494,\n",
       " 1658,\n",
       " 1084,\n",
       " 323,\n",
       " 447,\n",
       " 2221,\n",
       " 1144,\n",
       " 2274,\n",
       " 445,\n",
       " 653,\n",
       " 529,\n",
       " 1598,\n",
       " 493,\n",
       " 1401,\n",
       " 1949,\n",
       " 483,\n",
       " 1869,\n",
       " 655,\n",
       " 2459,\n",
       " 830,\n",
       " 1402,\n",
       " 1862,\n",
       " 1560,\n",
       " 721,\n",
       " 2051,\n",
       " 1722,\n",
       " 1198,\n",
       " 1429,\n",
       " 249,\n",
       " 2329,\n",
       " 393,\n",
       " 1472,\n",
       " 711,\n",
       " 295,\n",
       " 1108,\n",
       " 1612,\n",
       " 1477,\n",
       " 2383,\n",
       " 1660,\n",
       " 1534,\n",
       " 1712,\n",
       " 834,\n",
       " 1455,\n",
       " 200,\n",
       " 1289,\n",
       " 451,\n",
       " 1875,\n",
       " 207,\n",
       " 190,\n",
       " 1362,\n",
       " 1371,\n",
       " 2289,\n",
       " 789,\n",
       " 1321,\n",
       " 1703,\n",
       " 1674,\n",
       " 1692,\n",
       " 1844,\n",
       " 2479,\n",
       " 82,\n",
       " 1354,\n",
       " 1957,\n",
       " 383,\n",
       " 2429,\n",
       " 1646,\n",
       " 2142,\n",
       " 1728,\n",
       " 2303,\n",
       " 751,\n",
       " 785,\n",
       " 1790,\n",
       " 1133,\n",
       " 1088,\n",
       " 1247,\n",
       " 1868,\n",
       " 1209,\n",
       " 1826,\n",
       " 1691,\n",
       " 1106,\n",
       " 2168,\n",
       " 2241,\n",
       " 1197,\n",
       " 2355,\n",
       " 1906,\n",
       " 692,\n",
       " 849,\n",
       " 1853,\n",
       " 141,\n",
       " 205,\n",
       " 812,\n",
       " 2201,\n",
       " 1839,\n",
       " 1848,\n",
       " 818,\n",
       " 865,\n",
       " 1035,\n",
       " 1909,\n",
       " 1902,\n",
       " 738,\n",
       " 333,\n",
       " 1874,\n",
       " 1813,\n",
       " 2297,\n",
       " 33,\n",
       " 2425,\n",
       " 1661,\n",
       " 1461,\n",
       " 1811,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0bd1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    0,  ..., 2478, 2478, 2479],\n",
       "         [1084, 1104, 1288,  ...,  931,  933,  999]]),\n",
       " tensor([1., 1., 1.,  ..., 1., 1., 1.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "edge_index = from_scipy_sparse_matrix(adj)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0512d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a0aa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 1390)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b75bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 1984)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits['idx_train']), len(splits['idx_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15152f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(x=torch.tensor(feat, dtype=torch.float),\n",
    "            edge_index=edge_index[0],\n",
    "            y=torch.tensor(labels, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29783d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2480, 1390], edge_index=[2, 10100], y=[496])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "027a9fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1101905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2480])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36e8afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[idx_train] = 1\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask[idx_test] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3626e3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [2480] at index 0 does not match the shape of the indexed tensor [496] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [2480] at index 0 does not match the shape of the indexed tensor [496] at index 0"
     ]
    }
   ],
   "source": [
    "data.y[data.train_mask == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9269b2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fd4523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2480, 1390], edge_index=[2, 10100], y=[496], train_mask=[2480], test_mask=[2480])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbd9d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import APPNP\n",
    "\n",
    "class GraphSage(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.appnp = APPNP(K=100, alpha=0.1, dropout=0, cached=True, add_self_loops=True, normalize=False)\n",
    "        self.conv1 = SAGEConv(num_node_features, num_hidden)\n",
    "       # self.conv2 = SAGEConv(num_hidden, num_hidden)\n",
    "       # self.conv3 = SAGEConv(num_hidden, num_hidden)\n",
    "       # self.conv4 = SAGEConv(num_hidden, num_hidden)\n",
    "       # self.conv5 = SAGEConv(num_hidden, num_hidden)\n",
    "       # self.conv6 = SAGEConv(num_hidden, num_hidden)\n",
    "       # self.conv7 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv2 = SAGEConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.message_passing(x, edge_index, self.conv1)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv2)\n",
    "      #  x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv3)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv4)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv5)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv6)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv7)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.message_passing(x, edge_index, self.conv8)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def message_passing(self, x, edge_index, conv):\n",
    "        # Perform message passing with the given convolutional layer\n",
    "        return conv(x, edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d5d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import APPNP\n",
    "\n",
    "class GraphSage2(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.appnp = APPNP(K=100, alpha=0.1, dropout=0, cached=True, add_self_loops=True, normalize=False)\n",
    "        self.conv1 = SAGEConv(num_node_features, num_hidden)\n",
    "        self.conv2 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv3 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv4 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv5 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv6 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv7 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv8 = SAGEConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.message_passing(x, edge_index, self.conv1)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv2)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv3)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv4)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv5)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv6)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv7)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv8)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def message_passing(self, x, edge_index, conv):\n",
    "        # Perform message passing with the given convolutional layer\n",
    "        return conv(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99446e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5469511d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_mask\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_mask' is not defined"
     ]
    }
   ],
   "source": [
    "train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5854d25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_idx, test_idx \u001b[38;5;241m=\u001b[39m train_test_split(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39my)), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(len(data.y)), test_size=0.4, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15bb86d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_idx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_idx' is not defined"
     ]
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d629cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Best Validation Accuracy: 0.3333333333333333 at Epoch 157\n",
      "Test Accuracy: 0.2814070351758794\n",
      "Fold 2/10\n",
      "Best Validation Accuracy: 0.3333333333333333 at Epoch 0\n",
      "Test Accuracy: 0.2814070351758794\n",
      "Fold 3/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 164\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 4/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 5/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 6/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 7/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 8/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 9/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n",
      "Fold 10/10\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Test Accuracy: 0.2964824120603015\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model = None\n",
    "best_test_acc = 0.0\n",
    "best_test_predictions = None\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(len(data.y)), test_size=0.4, random_state=9)\n",
    "\n",
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for fold, (train_fold_idx, val_idx) in enumerate(kf.split(train_idx)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    model = GraphSage(num_node_features=data.x.shape[1],\n",
    "                      num_hidden=128,\n",
    "                      num_classes=(data.y.max() + 1).item()\n",
    "                      ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-3)\n",
    "\n",
    "    best_epoch = 0\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[train_idx[train_fold_idx]], data.y[train_idx[train_fold_idx]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).argmax(dim=1)\n",
    "            val_acc = pred[train_idx[val_idx]].eq(data.y[train_idx[val_idx]]).sum().item() / len(val_idx)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc} at Epoch {best_epoch}\")\n",
    "\n",
    "    # Load the best model for inference\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        acc = pred[test_idx].eq(data.y[test_idx]).sum().item() / len(test_idx)\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        if acc > best_test_acc:\n",
    "            best_test_acc = acc\n",
    "            best_test_predictions = pred[idx_test]\n",
    "           # np.savetxt('submissiontest.txt', best_test_predictions, fmt='%d')\n",
    "print(f\"Best Validation Accuracy: {best_val_acc} at Epoch {best_epoch}\")\n",
    "print(f\"Best Test Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0b34b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.26666666666666666 at Epoch 181\n",
      "Test Accuracy: 0.24120603015075376\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 16\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.4666666666666667 at Epoch 0\n",
      "Test Accuracy: 0.271356783919598\n",
      "Fold 20/20\n",
      "Best Validation Accuracy: 0.5714285714285714 at Epoch 8\n",
      "Test Accuracy: 0.27638190954773867\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model = None\n",
    "best_test_acc = 0.0\n",
    "best_test_predictions = None\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(len(data.y)), test_size=0.4, random_state=9)\n",
    "\n",
    "k_folds = 20\n",
    "kf = KFold(n_splits=k_folds, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for fold, (train_fold_idx, val_idx) in enumerate(kf.split(train_idx)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    model = GraphSage2(num_node_features=data.x.shape[1],\n",
    "                      num_hidden=64,\n",
    "                      num_classes=(data.y.max() + 1).item()\n",
    "                      ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-3)\n",
    "\n",
    "    best_epoch = 0\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[train_idx[train_fold_idx]], data.y[train_idx[train_fold_idx]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).argmax(dim=1)\n",
    "            val_acc = pred[train_idx[val_idx]].eq(data.y[train_idx[val_idx]]).sum().item() / len(val_idx)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc} at Epoch {best_epoch}\")\n",
    "\n",
    "    # Load the best model for inference\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        acc = pred[test_idx].eq(data.y[test_idx]).sum().item() / len(test_idx)\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        if acc > best_test_acc:\n",
    "            best_test_acc = acc\n",
    "            best_test_predictions = pred[idx_test]\n",
    "           # np.savetxt('submissiontest.txt', best_test_predictions, fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d3c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import APPNP\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(num_node_features, num_hidden, heads=64, dropout=0.4)\n",
    "        self.conv2 = GATConv(num_hidden * 64, num_classes, heads=1, concat=True, dropout=0.4)\n",
    "        self.appnp = APPNP(K=100, alpha=0.1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.appnp(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def message_passing(self, x, edge_index, conv):\n",
    "        # Perform message passing with the given convolutional layer\n",
    "        return conv(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465b9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Best Validation Accuracy: 0.3142857142857143 at Epoch 26\n",
      "Test Accuracy: 0.2953020134228188\n",
      "Fold 2/5\n",
      "Best Validation Accuracy: 0.34285714285714286 at Epoch 93\n",
      "Test Accuracy: 0.2953020134228188\n",
      "Fold 3/5\n",
      "Best Validation Accuracy: 0.34285714285714286 at Epoch 0\n",
      "Test Accuracy: 0.2953020134228188\n",
      "Fold 4/5\n",
      "Best Validation Accuracy: 0.34285714285714286 at Epoch 0\n",
      "Test Accuracy: 0.2953020134228188\n",
      "Fold 5/5\n",
      "Best Validation Accuracy: 0.34285714285714286 at Epoch 0\n",
      "Test Accuracy: 0.2953020134228188\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model = None\n",
    "best_test_acc = 0.0\n",
    "best_test_predictions = None\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(len(data.y)), test_size=0.3, random_state=123)\n",
    "\n",
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for fold, (train_fold_idx, val_idx) in enumerate(kf.split(train_idx)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    model = GAT(num_node_features=data.x.shape[1],\n",
    "                      num_hidden=150,\n",
    "                      num_classes=(data.y.max() + 1).item()\n",
    "                      ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=5e-4)\n",
    "\n",
    "    best_epoch = 0\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[train_idx[train_fold_idx]], data.y[train_idx[train_fold_idx]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).argmax(dim=1)\n",
    "            val_acc = pred[train_idx[val_idx]].eq(data.y[train_idx[val_idx]]).sum().item() / len(val_idx)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc} at Epoch {best_epoch}\")\n",
    "\n",
    "    # Load the best model for inference\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        acc = pred[test_idx].eq(data.y[test_idx]).sum().item() / len(test_idx)\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        if acc > best_test_acc:\n",
    "            best_test_acc = acc\n",
    "            best_test_predictions = pred[idx_test]\n",
    "          #  np.savetxt('submissiontest.txt', best_test_predictions, fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1cd0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.26666666666666666 at Epoch 128\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.3333333333333333 at Epoch 24\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.3333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 107\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.4 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   7%|▋         | 2/27 [00:34<07:14, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5 at Epoch 100\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  11%|█         | 3/27 [01:18<11:20, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  15%|█▍        | 4/27 [02:03<13:12, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.0001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.3015075376884422\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 183\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  19%|█▊        | 5/27 [02:47<13:55, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  22%|██▏       | 6/27 [03:33<14:12, 40.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  26%|██▌       | 7/27 [04:18<14:00, 42.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  30%|██▉       | 8/27 [05:03<13:37, 43.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  33%|███▎      | 9/27 [05:48<13:00, 43.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 2/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 3/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 4/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 5/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 6/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 7/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 8/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 9/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 10/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 11/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 12/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 13/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 14/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 15/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 16/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 17/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 18/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 19/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  37%|███▋      | 10/27 [06:31<12:18, 43.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Fold 1/20\n",
      "Best Validation Accuracy: 0.5333333333333333 at Epoch 0\n",
      "Best hyperparameters: {'num_hidden': 32, 'lr': 0.001, 'weight_decay': 0.0005}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GraphSage:\n\tsize mismatch for conv1.lin_l.weight: copying a param with shape torch.Size([32, 1390]) from checkpoint, the shape in current model is torch.Size([64, 1390]).\n\tsize mismatch for conv1.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv1.lin_r.weight: copying a param with shape torch.Size([32, 1390]) from checkpoint, the shape in current model is torch.Size([64, 1390]).\n\tsize mismatch for conv2.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv2.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv2.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv3.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv3.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv3.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv4.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv4.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv4.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv5.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv5.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv5.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv6.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv6.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv6.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv7.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv7.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv7.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv8.lin_l.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([7, 64]).\n\tsize mismatch for conv8.lin_r.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([7, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_hyperparameters)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Load the best model for inference\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model)\n\u001b[1;32m    128\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/graphsage/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GraphSage:\n\tsize mismatch for conv1.lin_l.weight: copying a param with shape torch.Size([32, 1390]) from checkpoint, the shape in current model is torch.Size([64, 1390]).\n\tsize mismatch for conv1.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv1.lin_r.weight: copying a param with shape torch.Size([32, 1390]) from checkpoint, the shape in current model is torch.Size([64, 1390]).\n\tsize mismatch for conv2.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv2.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv2.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv3.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv3.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv3.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv4.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv4.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv4.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv5.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv5.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv5.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv6.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv6.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv6.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv7.lin_l.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv7.lin_l.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv7.lin_r.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for conv8.lin_l.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([7, 64]).\n\tsize mismatch for conv8.lin_r.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([7, 64])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import APPNP\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GraphSage(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.appnp = APPNP(K=100, alpha=0.1, dropout=0, cached=True, add_self_loops=True, normalize=False)\n",
    "        self.conv1 = SAGEConv(num_node_features, num_hidden)\n",
    "        self.conv2 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv3 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv4 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv5 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv6 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv7 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv8 = SAGEConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.message_passing(x, edge_index, self.conv1)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv3)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv4)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv5)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv6)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv7)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv8)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def message_passing(self, x, edge_index, conv):\n",
    "        # Perform message passing with the given convolutional layer\n",
    "        return conv(x, edge_index)\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_hidden': [32, 64, 128],\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'weight_decay': [5e-4, 5e-3, 5e-2],\n",
    "}\n",
    "\n",
    "best_hyperparameters = None\n",
    "best_val_acc = 0.0\n",
    "best_val_acc = 0.0\n",
    "best_model = None\n",
    "best_test_acc = 0.0\n",
    "best_test_predictions = None\n",
    "\n",
    "total_iterations = len(hyperparameters['num_hidden']) * len(hyperparameters['lr']) * len(hyperparameters['weight_decay'])\n",
    "\n",
    "pbar = tqdm(total=total_iterations, desc=\"Grid Search Progress\")\n",
    "for num_hidden, lr, weight_decay in itertools.product(*hyperparameters.values()):\n",
    "    pbar.update(1)\n",
    "\n",
    "\n",
    "  \n",
    "    train_idx, test_idx = train_test_split(np.arange(len(data.y)), test_size=0.4, random_state=9)\n",
    "\n",
    "    k_folds = 20\n",
    "    kf = KFold(n_splits=k_folds, shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for fold, (train_fold_idx, val_idx) in enumerate(kf.split(train_idx)):\n",
    "        print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        model = GraphSage(num_node_features=data.x.shape[1],\n",
    "                        num_hidden=num_hidden,\n",
    "                        num_classes=(data.y.max() + 1).item()\n",
    "                        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_epoch = 0\n",
    "        for epoch in range(200):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out[train_idx[train_fold_idx]], data.y[train_idx[train_fold_idx]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(data).argmax(dim=1)\n",
    "                val_acc = pred[train_idx[val_idx]].eq(data.y[train_idx[val_idx]]).sum().item() / len(val_idx)\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_epoch = epoch\n",
    "                    best_hyperparameters = {'num_hidden': num_hidden, 'lr': lr, 'weight_decay': weight_decay}\n",
    "                    best_model = model.state_dict().copy()\n",
    "                    \n",
    "\n",
    "        \n",
    "\n",
    "        print(f\"Best Validation Accuracy: {best_val_acc} at Epoch {best_epoch}\")\n",
    "        print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "\n",
    "        # Load the best model for inference\n",
    "        model.load_state_dict(best_model)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).argmax(dim=1)\n",
    "            acc = pred[test_idx].eq(data.y[test_idx]).sum().item() / len(test_idx)\n",
    "            print(f\"Test Accuracy: {acc}\")\n",
    "            if acc > best_test_acc:\n",
    "                best_test_acc = acc\n",
    "                best_test_predictions = pred[idx_test]\n",
    "            # np.savetxt('submissiontest.txt', best_test_predictions, fmt='%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d030c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import APPNP\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GraphSage(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.appnp = APPNP(K=100, alpha=0.1, dropout=0, cached=True, add_self_loops=True, normalize=False)\n",
    "        self.conv1 = SAGEConv(num_node_features, num_hidden)\n",
    "        self.conv2 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv3 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv4 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv5 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv6 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv7 = SAGEConv(num_hidden, num_hidden)\n",
    "        self.conv8 = SAGEConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.message_passing(x, edge_index, self.conv1)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv3)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv4)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv5)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv6)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv7)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.message_passing(x, edge_index, self.conv8)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def message_passing(self, x, edge_index, conv):\n",
    "        # Perform message passing with the given convolutional layer\n",
    "        return conv(x, edge_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('graphsage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1cd7fe2092f8558eaeec7a344d6c72cd3491c14a7d06f3a2798a65abb497b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
